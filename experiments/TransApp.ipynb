{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ©2023 EDF\n",
    "Adrien PETRALIA - EDF R&D and Université Paris Cité (LIPADE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF & TransApp\n",
    "## A Transformer-Based Framework for Appliance Detection Using Smart Meter Consumption Series "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "root = Path(os.getcwd()).resolve().parents[0]\n",
    "sys.path.append(str(root))\n",
    "from experiments.data_utils import *\n",
    "from src.TransAppModel.TransApp import *\n",
    "from src.AD_Framework.Framework import *\n",
    "from src.utils.losses import *\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation of a TransApp Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_inst(m, win, dim_model, mode=\"pretraining\"):\n",
    "\n",
    "    TApp = TransApp(max_len=win, c_in=m,\n",
    "                    mode=\"pretraining\",\n",
    "                    n_embed_blocks=1, \n",
    "                    encoding_type='noencoding',\n",
    "                    n_encoder_layers=3,\n",
    "                    kernel_size=5,\n",
    "                    d_model=dim_model, pffn_ratio=2, n_head=4,\n",
    "                    prenorm=True, norm=\"LayerNorm\",\n",
    "                    activation='gelu',\n",
    "                    store_att=False, attn_dp_rate=0.2, head_dp_rate=0., dp_rate=0.2,\n",
    "                    att_param={'attenc_mask_diag': True, 'attenc_mask_flag': False, 'learnable_scale_enc': False},\n",
    "                    c_reconstruct=1, apply_gap=True, nb_class=2)\n",
    "\n",
    "    return TApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "TransApp                                                [1, 1, 1024]              --\n",
       "├─Sequential: 1-1                                       [1, 1024, 64]             --\n",
       "│    └─DilatedBlock: 2-1                                [1, 64, 1024]             --\n",
       "│    │    └─Sequential: 3-1                             [1, 64, 1024]             64,192\n",
       "│    └─Transpose: 2-2                                   [1, 1024, 64]             --\n",
       "├─Sequential: 1-2                                       [1, 1024, 64]             37,888\n",
       "│    └─EncoderLayer: 2-3                                [1, 1024, 64]             16,832\n",
       "│    │    └─LayerNorm: 3-4                              [1, 1024, 64]             (recursive)\n",
       "│    │    └─AttentionLayer: 3-3                         [1, 1024, 64]             16,640\n",
       "│    │    └─LayerNorm: 3-4                              [1, 1024, 64]             (recursive)\n",
       "│    │    └─LayerNorm: 3-11                             [1, 1024, 64]             (recursive)\n",
       "│    │    └─Dropout: 3-13                               [1, 1024, 64]             --\n",
       "│    │    └─PositionWiseFeedForward: 3-12               [1, 1024, 64]             (recursive)\n",
       "│    └─EncoderLayer: 2-5                                [1, 1024, 64]             (recursive)\n",
       "│    │    └─AttentionLayer: 3-15                        [1, 1024, 64]             (recursive)\n",
       "│    │    └─LayerNorm: 3-18                             [1, 1024, 64]             (recursive)\n",
       "│    │    └─Dropout: 3-20                               [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2                                  --                        --\n",
       "│    │    └─LayerNorm: 3-11                             [1, 1024, 64]             (recursive)\n",
       "│    │    └─PositionWiseFeedForward: 3-12               [1, 1024, 64]             (recursive)\n",
       "│    │    └─Dropout: 3-13                               [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2-5                                [1, 1024, 64]             (recursive)\n",
       "│    │    └─LayerNorm: 3-14                             [1, 1024, 64]             128\n",
       "│    │    └─AttentionLayer: 3-15                        [1, 1024, 64]             (recursive)\n",
       "│    └─EncoderLayer: 2                                  --                        --\n",
       "│    │    └─LayerNorm: 3-23                             [1, 1024, 64]             (recursive)\n",
       "│    │    └─Dropout: 3-25                               [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2                                  --                        --\n",
       "│    │    └─LayerNorm: 3-18                             [1, 1024, 64]             (recursive)\n",
       "│    │    └─PositionWiseFeedForward: 3-19               [1, 1024, 64]             16,576\n",
       "├─Sequential: 1-3                                       --                        --\n",
       "│    └─Transpose: 2-6                                   --                        --\n",
       "│    └─AdaptiveAvgPool1d: 2-7                           --                        --\n",
       "│    └─Flatten: 2-8                                     --                        --\n",
       "│    └─Linear: 2-9                                      --                        130\n",
       "│    └─Dropout: 2-10                                    --                        --\n",
       "├─Sequential: 1                                         --                        --\n",
       "│    └─EncoderLayer: 2                                  --                        --\n",
       "│    │    └─Dropout: 3-20                               [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2-11                               [1, 1024, 64]             128\n",
       "│    │    └─LayerNorm: 3-21                             [1, 1024, 64]             128\n",
       "│    │    └─AttentionLayer: 3-22                        [1, 1024, 64]             16,640\n",
       "│    │    └─LayerNorm: 3-23                             [1, 1024, 64]             (recursive)\n",
       "│    │    └─PositionWiseFeedForward: 3-24               [1, 1024, 64]             16,576\n",
       "│    │    └─Dropout: 3-25                               [1, 1024, 64]             --\n",
       "│    └─LayerNorm: 2-12                                  [1, 1024, 64]             128\n",
       "├─Sequential: 1-4                                       [1, 1024, 1]              --\n",
       "│    └─Linear: 2-13                                     [1, 1024, 1]              65\n",
       "│    └─Dropout: 2-14                                    [1, 1024, 1]              --\n",
       "=========================================================================================================\n",
       "Total params: 164,931\n",
       "Trainable params: 164,931\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 65.74\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 13.12\n",
       "Params size (MB): 0.52\n",
       "Estimated Total Size (MB): 13.66\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransApp = get_model_inst(m=5, win=1024, dim_model=64, mode=\"pretraining\")\n",
    "\n",
    "summary(TransApp, input_size=(1, 5, 1024), mode=\"train\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9202,  1.3643,  0.6505,  ..., -0.2121, -0.2282,  2.2120]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy Forward\n",
    "TransApp(torch.rand(1, 5, 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-supervised pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pretraining = CER_get_data_pretraining(exo_variable=['hours_cos', 'hours_sin', 'days_cos', 'days_sin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_dataset = TSDataset(X_train, scaler=True, scale_dim=[0])\n",
    "train_loader = torch.utils.data.DataLoader(pretraining_dataset, batch_size=dict_params['batch_size'], shuffle=True)\n",
    "\n",
    "dict_params = {'lr': 1e-4, 'wd': 1e-4, 'batch_size': 16, 'epochs': 20}\n",
    "save_path = '' # To complete\n",
    "\n",
    "model_pretrainer = self_pretrainer(TransApp,                                     \n",
    "                                   train_loader, valid_loader=None,\n",
    "                                   learning_rate=dict_params['lr'], weight_decay=dict_params['wd'],\n",
    "                                   name_scheduler='CosineAnnealingLR',\n",
    "                                   dict_params_scheduler={'T_max': dict_params['epochs'], 'eta_min': 1e-6},\n",
    "                                   warmup_duration=None,\n",
    "                                   criterion=MaskedMSELoss(type_loss='L1'), mask=GeomMask,\n",
    "                                   device=\"cuda\", all_gpu=False,\n",
    "                                   verbose=True, plotloss=False, \n",
    "                                   save_fig=False, path_fig=None,\n",
    "                                   save_only_core=False,\n",
    "                                   save_checkpoint=True, path_checkpoint=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrainer.train(dict_params['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning to a Appliance Detection cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "TransApp                                                [1, 2]                    65\n",
       "├─Sequential: 1-1                                       [1, 1024, 64]             --\n",
       "│    └─DilatedBlock: 2-1                                [1, 64, 1024]             --\n",
       "│    │    └─Sequential: 3-1                             [1, 64, 1024]             64,192\n",
       "│    └─Transpose: 2-2                                   [1, 1024, 64]             --\n",
       "├─Sequential: 1-2                                       [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2-3                                [1, 1024, 64]             --\n",
       "│    │    └─LayerNorm: 3-2                              [1, 1024, 64]             128\n",
       "│    │    └─AttentionLayer: 3-3                         [1, 1024, 64]             16,640\n",
       "│    │    └─LayerNorm: 3-4                              [1, 1024, 64]             128\n",
       "│    │    └─PositionWiseFeedForward: 3-5                [1, 1024, 64]             16,576\n",
       "│    │    └─Dropout: 3-6                                [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2-4                                [1, 1024, 64]             --\n",
       "│    │    └─LayerNorm: 3-7                              [1, 1024, 64]             128\n",
       "│    │    └─AttentionLayer: 3-8                         [1, 1024, 64]             16,640\n",
       "│    │    └─LayerNorm: 3-9                              [1, 1024, 64]             128\n",
       "│    │    └─PositionWiseFeedForward: 3-10               [1, 1024, 64]             16,576\n",
       "│    │    └─Dropout: 3-11                               [1, 1024, 64]             --\n",
       "│    └─EncoderLayer: 2-5                                [1, 1024, 64]             --\n",
       "│    │    └─LayerNorm: 3-12                             [1, 1024, 64]             128\n",
       "│    │    └─AttentionLayer: 3-13                        [1, 1024, 64]             16,640\n",
       "│    │    └─LayerNorm: 3-14                             [1, 1024, 64]             128\n",
       "│    │    └─PositionWiseFeedForward: 3-15               [1, 1024, 64]             16,576\n",
       "│    │    └─Dropout: 3-16                               [1, 1024, 64]             --\n",
       "│    └─LayerNorm: 2-6                                   [1, 1024, 64]             128\n",
       "├─Sequential: 1-3                                       [1, 2]                    --\n",
       "│    └─Transpose: 2-7                                   [1, 64, 1024]             --\n",
       "│    └─AdaptiveAvgPool1d: 2-8                           [1, 64, 1]                --\n",
       "│    └─Flatten: 2-9                                     [1, 64]                   --\n",
       "│    └─Linear: 2-10                                     [1, 2]                    130\n",
       "│    └─Dropout: 2-11                                    [1, 2]                    --\n",
       "=========================================================================================================\n",
       "Total params: 164,931\n",
       "Trainable params: 164,931\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 65.31\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 19.40\n",
       "Params size (MB): 0.66\n",
       "Estimated Total Size (MB): 20.08\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TransApp.mode = \"classif\"\n",
    "\n",
    "summary(TransApp, input_size=(1, 5, 1024), mode=\"train\", device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_tuple = CER_get_data_case('cooker_case', seed=0, exo_variable=['hours_cos', 'hours_sin', 'days_cos', 'days_sin'], win=1024, ratio_resample=0.8, group='residential')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scliced data\n",
    "X_train = datas_tuple[0]\n",
    "y_train = datas_tuple[1]\n",
    "X_valid = datas_tuple[2]\n",
    "y_valid = datas_tuple[3]\n",
    "X_test  = datas_tuple[4]\n",
    "y_test  = datas_tuple[5]\n",
    "\n",
    "# Entire curves data\n",
    "X_train_voter = datas_tuple[6]\n",
    "y_train_voter = datas_tuple[7]\n",
    "X_valid_voter = datas_tuple[8]\n",
    "y_valid_voter = datas_tuple[9]\n",
    "X_test_voter  = datas_tuple[10]\n",
    "y_test_voter  = datas_tuple[11]\n",
    "\n",
    "# Dataset\n",
    "train_dataset = TSDataset(X_train, y_train, scaler=True, scale_dim=[0])\n",
    "valid_dataset = TSDataset(X_valid, y_valid, scaler=True, scale_dim=[0])\n",
    "test_dataset  = TSDataset(X_test, y_test,   scaler=True, scale_dim=[0])\n",
    "\n",
    "dict_params = {'lr': 1e-4, 'wd': 1e-3, 'batch_size': 16, 'epochs': 15, 'p_es': 5, 'p_rlr': 3, 'n_warmup_epochs': 0}\n",
    "save_path = '' # To complete\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=dict_params['batch_size'], shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model_trainer = AD_Framework(TransApp,\n",
    "                             train_loader=train_loader, valid_loader=valid_loader,\n",
    "                             learning_rate=dict_params['lr'], weight_decay=dict_params['wd'],\n",
    "                             criterion=nn.CrossEntropyLoss(),\n",
    "                             patience_es=dict_params['p_es'], patience_rlr=dict_params['p_rlr'],\n",
    "                             f_metrics=getmetrics(),\n",
    "                             n_warmup_epochs=dict_params['n_warmup_epochs'],\n",
    "                             scale_by_subseq_in_voter=True, scale_dim=[0],\n",
    "                             verbose=True, plotloss=False, \n",
    "                             save_fig=False, path_fig=None,\n",
    "                             device=\"cuda\", all_gpu=True,\n",
    "                             save_checkpoint=True, path_checkpoint=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer.train(dict_params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ eval last model ============#\n",
    "model_trainer.evaluate(torch.utils.data.DataLoader(test_dataset, batch_size=1), mask='test_metrics_lastmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#============ restore best weight and evaluate ============#    \n",
    "model_trainer.restore_best_weights()\n",
    "model_trainer.evaluate(torch.utils.data.DataLoader(test_dataset, batch_size=1))\n",
    "\n",
    "#============ find best quantile on valid dataset ============#\n",
    "model_trainer.ADFFindBestQuantile(TSDataset(X_valid_voter, y_valid_voter), m=m, win=win)\n",
    "quant_metric = model_trainer.ADFvoter_proba(TSDataset(X_test_voter, y_test_voter), m=m, win=win)\n",
    "print(quant_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-1.8.1]",
   "language": "python",
   "name": "conda-env-pytorch-1.8.1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
